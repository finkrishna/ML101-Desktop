{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from visdom import Visdom\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "T = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_data = torchvision.datasets.MNIST('mnist_data', transform = T, download = True)\n",
    "mnist_dataloader = torch.utils.data.DataLoader(mnist_data,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnet,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28,100)\n",
    "        self.linear2 = nn.Linear(100,50)\n",
    "        self.final_linear = nn.Linear(50,10)\n",
    "        \n",
    "        self.relu = nn.ReLU\n",
    "        \n",
    "    def forward(self,images):\n",
    "        x = images.view(-1,28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.final_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnet()\n",
    "cec_loss = nn.CrossEntropyLoss()\n",
    "params = model.parameters()\n",
    "optimizer = optim.Adam(params=params,lr=0.001)\n",
    "\n",
    "n_epochs = 3\n",
    "n_iterations =0\n",
    "\n",
    "#vis = Visdom()\n",
    "#vis_window = vis.line(np.array([0]),np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReLU' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1d32c45b75de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-1be167565e86>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \"\"\"\n\u001b[0;32m-> 1350\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range (n_epochs):\n",
    "    for i, (images,labels) in enumerate(mnist_dataloader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        output = model(images)\n",
    "        \n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = cec_loss(output,labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimiser.step()\n",
    "        n_iterations +=1\n",
    "        \n",
    "        #vis.line(np.array([loss.item()]),np.array([n_iterations]),win=vis_window,update='append')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ CNN using MNIST ###########\n",
    "\n",
    "n_batch = 64\n",
    "learning_rate = 0.01\n",
    "n_epoch = 3\n",
    "n_print = 10\n",
    "\n",
    "#### Part I : Loading Your Data \n",
    "\n",
    "T = torchvision.transforms.ToTensor()\n",
    "train_data = torchvision.datasets.MNIST('mnist_data',train=True,download=True,transform=T)\n",
    "val_data = torchvision.datasets.MNIST('mnist_data',train=False,download=True,transform=T)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_data,batch_size = n_batch)\n",
    "val_dl = torch.utils.data.DataLoader(val_data,batch_size = n_batch)\n",
    "\n",
    "#### Part II : Writing the Network\n",
    "class myCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(myCNN,self).__init__()\n",
    "    self.cnn1 = nn.Conv2d(1,3,3)\n",
    "    self.cnn2 = nn.Conv2d(3,2,5)\n",
    "    self.linear = nn.Linear(968,10)\n",
    "    self.relu = nn.ReLU()\n",
    "  \n",
    "  def forward(self,x):\n",
    "    n = x.size(0)\n",
    "    x = self.relu(self.cnn1(x))\n",
    "    x = self.relu(self.cnn2(x))\n",
    "    x = x.view(n,-1)\n",
    "    x = self.linear(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Batch : 10 Loss : 0.9844905734062195 Accuracy : 79.0 %\n",
      "Epoch : 1 Batch : 20 Loss : 0.9413279294967651 Accuracy : 81.0 %\n",
      "Epoch : 1 Batch : 30 Loss : 0.28883400559425354 Accuracy : 84.0 %\n",
      "Epoch : 1 Batch : 40 Loss : 0.21741244196891785 Accuracy : 83.0 %\n",
      "Epoch : 1 Batch : 50 Loss : 0.23827940225601196 Accuracy : 86.0 %\n",
      "Epoch : 1 Batch : 60 Loss : 0.4456512928009033 Accuracy : 87.0 %\n",
      "Epoch : 1 Batch : 70 Loss : 0.2974686920642853 Accuracy : 87.0 %\n",
      "Epoch : 1 Batch : 80 Loss : 0.38889527320861816 Accuracy : 88.0 %\n",
      "Epoch : 1 Batch : 90 Loss : 0.2620828151702881 Accuracy : 89.0 %\n",
      "Epoch : 1 Batch : 100 Loss : 0.16384395956993103 Accuracy : 89.0 %\n",
      "Epoch : 1 Batch : 110 Loss : 0.5347982048988342 Accuracy : 89.0 %\n",
      "Epoch : 1 Batch : 120 Loss : 0.30175960063934326 Accuracy : 90.0 %\n",
      "Epoch : 1 Batch : 130 Loss : 0.29319605231285095 Accuracy : 91.0 %\n",
      "Epoch : 1 Batch : 140 Loss : 0.3883541524410248 Accuracy : 89.0 %\n",
      "Epoch : 1 Batch : 150 Loss : 0.33085817098617554 Accuracy : 90.0 %\n",
      "Epoch : 1 Batch : 160 Loss : 0.527061939239502 Accuracy : 91.0 %\n",
      "Epoch : 1 Batch : 170 Loss : 0.31507158279418945 Accuracy : 88.0 %\n",
      "Epoch : 1 Batch : 180 Loss : 0.26171061396598816 Accuracy : 91.0 %\n",
      "Epoch : 1 Batch : 190 Loss : 0.21909797191619873 Accuracy : 90.0 %\n",
      "Epoch : 1 Batch : 200 Loss : 0.29813656210899353 Accuracy : 89.0 %\n",
      "Epoch : 1 Batch : 210 Loss : 0.28546738624572754 Accuracy : 92.0 %\n",
      "Epoch : 1 Batch : 220 Loss : 0.2886278033256531 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 230 Loss : 0.41530686616897583 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 240 Loss : 0.216694638133049 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 250 Loss : 0.7677778601646423 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 260 Loss : 0.06296142935752869 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 270 Loss : 0.20929139852523804 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 280 Loss : 0.17890819907188416 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 290 Loss : 0.09307092428207397 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 300 Loss : 0.12536472082138062 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 310 Loss : 0.43501704931259155 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 320 Loss : 0.14400255680084229 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 330 Loss : 0.1946357786655426 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 340 Loss : 0.1656980812549591 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 350 Loss : 0.032826125621795654 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 360 Loss : 0.13433429598808289 Accuracy : 93.0 %\n",
      "Epoch : 1 Batch : 370 Loss : 0.19426880776882172 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 380 Loss : 0.247357577085495 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 390 Loss : 0.26043206453323364 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 400 Loss : 0.28018808364868164 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 410 Loss : 0.07755307853221893 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 420 Loss : 0.1834951937198639 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 430 Loss : 0.23143768310546875 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 440 Loss : 0.3483012318611145 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 450 Loss : 0.161832794547081 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 460 Loss : 0.2369958758354187 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 470 Loss : 0.2666679620742798 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 480 Loss : 0.23061980307102203 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 490 Loss : 0.4394475817680359 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 500 Loss : 0.2582210898399353 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 510 Loss : 0.03560888022184372 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 520 Loss : 0.2130417823791504 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 530 Loss : 0.03814569488167763 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 540 Loss : 0.30221331119537354 Accuracy : 94.0 %\n",
      "Epoch : 1 Batch : 550 Loss : 0.17218361794948578 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 560 Loss : 0.04092849791049957 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 570 Loss : 0.37039074301719666 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 580 Loss : 0.30239617824554443 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 590 Loss : 0.17112663388252258 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 600 Loss : 0.17038480937480927 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 610 Loss : 0.1406315714120865 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 620 Loss : 0.25122326612472534 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 630 Loss : 0.19717244803905487 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 640 Loss : 0.03487556800246239 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 650 Loss : 0.23481371998786926 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 660 Loss : 0.1520262211561203 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 670 Loss : 0.414369136095047 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 680 Loss : 0.11031559109687805 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 690 Loss : 0.25558388233184814 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 700 Loss : 0.11688998341560364 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 710 Loss : 0.1995277851819992 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 720 Loss : 0.13689380884170532 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 730 Loss : 0.11064685881137848 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 740 Loss : 0.11919393390417099 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 750 Loss : 0.0795484334230423 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 760 Loss : 0.06481709331274033 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 770 Loss : 0.14135369658470154 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 780 Loss : 0.2901950180530548 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 790 Loss : 0.264783650636673 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 800 Loss : 0.15656863152980804 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 810 Loss : 0.049206025898456573 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 820 Loss : 0.07927289605140686 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 830 Loss : 0.09577743709087372 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 840 Loss : 0.2255488634109497 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 850 Loss : 0.13904671370983124 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 860 Loss : 0.1374180167913437 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 870 Loss : 0.18334785103797913 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 880 Loss : 0.15946528315544128 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 890 Loss : 0.09585655480623245 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 900 Loss : 0.03902304545044899 Accuracy : 96.0 %\n",
      "Epoch : 1 Batch : 910 Loss : 0.019269302487373352 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 920 Loss : 0.14535948634147644 Accuracy : 95.0 %\n",
      "Epoch : 1 Batch : 930 Loss : 0.1180078312754631 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 10 Loss : 0.09293417632579803 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 20 Loss : 0.28764283657073975 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 30 Loss : 0.041537463665008545 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 40 Loss : 0.08273651450872421 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 50 Loss : 0.04776638746261597 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 60 Loss : 0.1732008457183838 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 70 Loss : 0.11558748781681061 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 80 Loss : 0.07031816244125366 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 90 Loss : 0.1510593295097351 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 100 Loss : 0.08876411616802216 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 110 Loss : 0.22998452186584473 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 120 Loss : 0.14547224342823029 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 130 Loss : 0.19723032414913177 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 140 Loss : 0.25091180205345154 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 150 Loss : 0.08627784252166748 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 160 Loss : 0.1573060154914856 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 170 Loss : 0.1023770347237587 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 180 Loss : 0.0980105772614479 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 190 Loss : 0.09738650172948837 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 200 Loss : 0.13863691687583923 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 210 Loss : 0.3249293565750122 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 220 Loss : 0.056203778833150864 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 230 Loss : 0.16134697198867798 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 240 Loss : 0.12709897756576538 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 250 Loss : 0.43496066331863403 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 260 Loss : 0.018181636929512024 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 270 Loss : 0.1625128537416458 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 280 Loss : 0.08318134397268295 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 290 Loss : 0.07792478054761887 Accuracy : 97.0 %\n",
      "Epoch : 2 Batch : 300 Loss : 0.05988183245062828 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 310 Loss : 0.32399433851242065 Accuracy : 96.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 Batch : 320 Loss : 0.029449403285980225 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 330 Loss : 0.0854913666844368 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 340 Loss : 0.09478650987148285 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 350 Loss : 0.008619889616966248 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 360 Loss : 0.12984785437583923 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 370 Loss : 0.15465041995048523 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 380 Loss : 0.11745168268680573 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 390 Loss : 0.14492034912109375 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 400 Loss : 0.15662527084350586 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 410 Loss : 0.058758992701768875 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 420 Loss : 0.1311989724636078 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 430 Loss : 0.23649631440639496 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 440 Loss : 0.15116703510284424 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 450 Loss : 0.11180561780929565 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 460 Loss : 0.1300801932811737 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 470 Loss : 0.15175984799861908 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 480 Loss : 0.10189134627580643 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 490 Loss : 0.18056216835975647 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 500 Loss : 0.15817925333976746 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 510 Loss : 0.010889198631048203 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 520 Loss : 0.06684752553701401 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 530 Loss : 0.028333108872175217 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 540 Loss : 0.19239503145217896 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 550 Loss : 0.09992283582687378 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 560 Loss : 0.02849416807293892 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 570 Loss : 0.24777992069721222 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 580 Loss : 0.22954584658145905 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 590 Loss : 0.13254930078983307 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 600 Loss : 0.18329574167728424 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 610 Loss : 0.11632546782493591 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 620 Loss : 0.23541340231895447 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 630 Loss : 0.12020710110664368 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 640 Loss : 0.06624626368284225 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 650 Loss : 0.2937479615211487 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 660 Loss : 0.16017001867294312 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 670 Loss : 0.3039005994796753 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 680 Loss : 0.10577990114688873 Accuracy : 94.0 %\n",
      "Epoch : 2 Batch : 690 Loss : 0.2036944031715393 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 700 Loss : 0.1072680652141571 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 710 Loss : 0.10274806618690491 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 720 Loss : 0.12815064191818237 Accuracy : 97.0 %\n",
      "Epoch : 2 Batch : 730 Loss : 0.05151304975152016 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 740 Loss : 0.1135839894413948 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 750 Loss : 0.09465114772319794 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 760 Loss : 0.024093173444271088 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 770 Loss : 0.12447177618741989 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 780 Loss : 0.2706555128097534 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 790 Loss : 0.27892452478408813 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 800 Loss : 0.14811569452285767 Accuracy : 94.0 %\n",
      "Epoch : 2 Batch : 810 Loss : 0.02186073362827301 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 820 Loss : 0.06302902102470398 Accuracy : 95.0 %\n",
      "Epoch : 2 Batch : 830 Loss : 0.05804002657532692 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 840 Loss : 0.14962559938430786 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 850 Loss : 0.17311236262321472 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 860 Loss : 0.08215705305337906 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 870 Loss : 0.04822375625371933 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 880 Loss : 0.14845354855060577 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 890 Loss : 0.07571109384298325 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 900 Loss : 0.013714291155338287 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 910 Loss : 0.014152683317661285 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 920 Loss : 0.11224139481782913 Accuracy : 96.0 %\n",
      "Epoch : 2 Batch : 930 Loss : 0.07787430286407471 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 10 Loss : 0.08126069605350494 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 20 Loss : 0.2097608596086502 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 30 Loss : 0.060148872435092926 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 40 Loss : 0.03276047110557556 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 50 Loss : 0.028198212385177612 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 60 Loss : 0.1135157123208046 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 70 Loss : 0.12637017667293549 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 80 Loss : 0.06856437772512436 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 90 Loss : 0.141880065202713 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 100 Loss : 0.05391464754939079 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 110 Loss : 0.15053915977478027 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 120 Loss : 0.1334562599658966 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 130 Loss : 0.1405671089887619 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 140 Loss : 0.21896164119243622 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 150 Loss : 0.055325545370578766 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 160 Loss : 0.2346145659685135 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 170 Loss : 0.07688399404287338 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 180 Loss : 0.105256088078022 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 190 Loss : 0.12737590074539185 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 200 Loss : 0.10578948259353638 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 210 Loss : 0.20549353957176208 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 220 Loss : 0.03078470006585121 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 230 Loss : 0.10270051658153534 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 240 Loss : 0.11412203311920166 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 250 Loss : 0.36984992027282715 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 260 Loss : 0.029359765350818634 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 270 Loss : 0.13902564346790314 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 280 Loss : 0.13840961456298828 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 290 Loss : 0.08017780631780624 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 300 Loss : 0.06021587550640106 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 310 Loss : 0.19318071007728577 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 320 Loss : 0.02011694386601448 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 330 Loss : 0.10938955843448639 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 340 Loss : 0.08526413887739182 Accuracy : 97.0 %\n",
      "Epoch : 3 Batch : 350 Loss : 0.0077507272362709045 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 360 Loss : 0.13856075704097748 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 370 Loss : 0.17924760282039642 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 380 Loss : 0.06388341635465622 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 390 Loss : 0.12338293343782425 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 400 Loss : 0.10029890388250351 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 410 Loss : 0.059903353452682495 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 420 Loss : 0.0934339091181755 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 430 Loss : 0.2552012801170349 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 440 Loss : 0.10420383512973785 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 450 Loss : 0.08193742483854294 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 460 Loss : 0.06988650560379028 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 470 Loss : 0.16396312415599823 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 480 Loss : 0.1182016134262085 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 490 Loss : 0.23471099138259888 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 500 Loss : 0.11213743686676025 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 510 Loss : 0.011130187660455704 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 520 Loss : 0.06737371534109116 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 530 Loss : 0.024201858788728714 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 540 Loss : 0.13143613934516907 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 550 Loss : 0.09915932267904282 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 560 Loss : 0.03774335980415344 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 570 Loss : 0.21684995293617249 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 580 Loss : 0.19232535362243652 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 590 Loss : 0.15043920278549194 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 600 Loss : 0.1884886622428894 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 610 Loss : 0.0989493653178215 Accuracy : 96.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 Batch : 620 Loss : 0.19036629796028137 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 630 Loss : 0.09044201672077179 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 640 Loss : 0.061783719807863235 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 650 Loss : 0.20946384966373444 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 660 Loss : 0.11767151951789856 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 670 Loss : 0.2878120541572571 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 680 Loss : 0.08705370128154755 Accuracy : 94.0 %\n",
      "Epoch : 3 Batch : 690 Loss : 0.1763225644826889 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 700 Loss : 0.14983642101287842 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 710 Loss : 0.09963157027959824 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 720 Loss : 0.1018080934882164 Accuracy : 97.0 %\n",
      "Epoch : 3 Batch : 730 Loss : 0.031197281554341316 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 740 Loss : 0.11245545744895935 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 750 Loss : 0.10105624794960022 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 760 Loss : 0.03825457766652107 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 770 Loss : 0.113102987408638 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 780 Loss : 0.26611149311065674 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 790 Loss : 0.2694335877895355 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 800 Loss : 0.1195557713508606 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 810 Loss : 0.0465376079082489 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 820 Loss : 0.029982395470142365 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 830 Loss : 0.04831055551767349 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 840 Loss : 0.15409955382347107 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 850 Loss : 0.10040193051099777 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 860 Loss : 0.06581780314445496 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 870 Loss : 0.02925165742635727 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 880 Loss : 0.10595999658107758 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 890 Loss : 0.13491493463516235 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 900 Loss : 0.01393478736281395 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 910 Loss : 0.012920446693897247 Accuracy : 95.0 %\n",
      "Epoch : 3 Batch : 920 Loss : 0.09599466621875763 Accuracy : 96.0 %\n",
      "Epoch : 3 Batch : 930 Loss : 0.08530230820178986 Accuracy : 96.0 %\n"
     ]
    }
   ],
   "source": [
    "#### Part III : Writing the main Training loop\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "mycnn = myCNN()\n",
    "cec = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mycnn.parameters(),lr = learning_rate)\n",
    "\n",
    "def validate(model,data):\n",
    "  # To get validation accuracy = (correct/total)*100.\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for i,(images,labels) in enumerate(data):\n",
    "    images = Variable(images)\n",
    "    x = model(images)\n",
    "    value,pred = torch.max(x,1)\n",
    "    pred = pred.data.cpu()\n",
    "    total += x.size(0)\n",
    "    correct += torch.sum(pred == labels)\n",
    "  return correct*100./total\n",
    "\n",
    "for e in range(n_epoch):\n",
    "  for i,(images,labels) in enumerate(train_dl):\n",
    "    images = Variable(images)\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    pred = mycnn(images)\n",
    "    loss = cec(pred,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1) % n_print == 0:\n",
    "      accuracy = float(validate(mycnn,val_dl))\n",
    "      print('Epoch :',e+1,'Batch :',i+1,'Loss :',float(loss.data),'Accuracy :',accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
